{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação e Regressão com Redes Neurais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/brunomaciel/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Adaptação para utilizar a sintaxe do TensorFlor 1.x no TensorFlow 2.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> \n",
    "## 1. Perceptron de 1 Camada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dados de entrada (Operador AND)\n",
    "x = np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]])\n",
    "y = np.array([[0.], [0.], [0.], [1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-e312bcf0eff3>:8: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# Inicializa os pesos\n",
    "w = tf.Variable(tf.zeros([2,1], dtype=tf.float64))\n",
    "\n",
    "# Define o calculo da camada de saída\n",
    "output_layer = tf.matmul(x, w)\n",
    "\n",
    "# Define a função de ativação (step function)\n",
    "output_layer_result = tf.cast(tf.to_float(tf.math.greater_equal(output_layer, 1)), tf.float64)\n",
    " # greater_equal: retorna True/False\n",
    " # to_float: transforma em float\n",
    " # cast: transforma em um formato especifico\n",
    "\n",
    "# Define o calculo do Erro\n",
    "erro = tf.subtract(y, output_layer_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peno_n+1 = peso_n + (learn_rate * entradas * erro)\n",
    "delta = tf.matmul(x, erro, transpose_a = True)\n",
    "\n",
    "compute_new_w = tf.assign(w, tf.add(w, tf.multiply(delta, 0.1)))\n",
    " # assign: atualiza o valor de w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Erro = 1.0\n",
      "Epoch 1: Erro = 1.0\n",
      "Epoch 2: Erro = 1.0\n",
      "Epoch 3: Erro = 1.0\n",
      "Epoch 4: Erro = 1.0\n",
      "Epoch 5: Erro = 0.0\n"
     ]
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)\n",
    "    #print(sess.run(output_layer), '\\n\\nPós Func Ativação:')\n",
    "    #print(sess.run(output_layer_result), '\\n\\nErro:')\n",
    "    #print(sess.run(erro), '\\n\\nNovo Peso:')\n",
    "    #print(sess.run(compute_new_w), '\\n')\n",
    "    \n",
    "    for i in range(15):\n",
    "        erro_total, _ = sess.run((erro, compute_new_w))\n",
    "         # erro_total é vetor com o erro de cada um dos registros\n",
    "        erro_soma = tf.reduce_sum(erro_total) # calcula o somatorio do erro de todos os registros\n",
    "        print('Epoch {}: Erro = {}'.format(i, sess.run(erro_soma)))\n",
    "        \n",
    "        if erro_soma.eval() == 0:\n",
    "            break\n",
    "    \n",
    "    w_final = sess.run(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0.5]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "# Realiza a previsão\n",
    "output_layer_predict = tf.matmul(x, w_final)\n",
    "output_layer_result_predict = tf.cast(tf.to_float(tf.math.greater_equal(output_layer_predict, 1)), tf.float64)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)\n",
    "    print(sess.run(output_layer_result_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/> \n",
    "## 2. Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Classificação Binária (Operador XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dados de entrada (Operador XOR)\n",
    "x = np.array([[0.,0.],[0.,1.],[1.,0.],[1.,1.]], dtype=np.float32)\n",
    "y = np.array([[0.], [1.], [1.], [0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define estrutura da RNN\n",
    "input_neurons = 2\n",
    "hidden_neurons = 3\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os placeholders de entrada e saída\n",
    "x_ph = tf.placeholder(dtype=tf.float32, shape=(4, input_neurons), name='x_placeholder')\n",
    "y_ph = tf.placeholder(dtype=tf.float32, shape=(4, output_neurons), name='y_placeholder')\n",
    "\n",
    "# Inicializa os pesos e bias\n",
    "w = {'hidden': tf.Variable(tf.random_normal([input_neurons, hidden_neurons]), name='w_hidden'),\n",
    "     'output': tf.Variable(tf.random_normal([hidden_neurons, output_neurons]), name='w_output')}\n",
    "\n",
    "bias = {'hidden': tf.Variable(tf.random_normal([hidden_neurons]), name='bias_hidden'),\n",
    "        'output': tf.Variable(tf.random_normal([output_neurons]), name='bias_output')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo de FeedForward\n",
    "hidden_layer = tf.add(tf.matmul(x_ph, w['hidden']), bias['hidden'])\n",
    "hidden_layer_result = tf.sigmoid(hidden_layer)\n",
    "\n",
    "output_layer = tf.add(tf.matmul(hidden_layer_result, w['output']), bias['output'])\n",
    "output_layer_result = tf.sigmoid(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo do Erro\n",
    "erro = tf.losses.mean_squared_error(y_ph, output_layer_result)\n",
    "\n",
    "# Processo de BackPropagation\n",
    "otimizador = tf.train.GradientDescentOptimizer(learning_rate=0.3).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.08340046554803848\n",
      "Epoch 200: 0.05140066146850586\n",
      "Epoch 400: 0.046587347984313965\n",
      "Epoch 600: 0.04288885369896889\n",
      "Epoch 800: 0.04011023789644241\n",
      "Epoch 1000: 0.03799761086702347\n",
      "Epoch 1200: 0.03621741384267807\n",
      "Epoch 1400: 0.03416530042886734\n",
      "Epoch 1600: 0.03015596978366375\n",
      "Epoch 1800: 0.02274371311068535\n",
      "Epoch 2000: 0.015623115003108978\n",
      "Epoch 2200: 0.010914630256593227\n",
      "Epoch 2400: 0.007959224283695221\n",
      "Epoch 2600: 0.006046987138688564\n",
      "Epoch 2800: 0.004760916344821453\n",
      "Epoch 3000: 0.0038623830769211054\n",
      "Epoch 3200: 0.00321214203722775\n",
      "Epoch 3400: 0.002726680366322398\n",
      "Epoch 3600: 0.0023542630951851606\n",
      "Epoch 3800: 0.002061778912320733\n",
      "Epoch 4000: 0.0018273736350238323\n",
      "Epoch 4200: 0.0016361856833100319\n",
      "Epoch 4400: 0.0014778526965528727\n",
      "Epoch 4600: 0.001344967051409185\n",
      "Epoch 4800: 0.0012321219546720386\n",
      "Epoch 5000: 0.001135295140556991\n",
      "Epoch 5200: 0.001051444560289383\n",
      "Epoch 5400: 0.0009782301494851708\n",
      "Epoch 5600: 0.00091382279060781\n",
      "Epoch 5800: 0.0008567879558540881\n",
      "Epoch 6000: 0.0008059712708927691\n",
      "Epoch 6200: 0.0007604464190080762\n",
      "Epoch 6400: 0.0007194573408924043\n",
      "Epoch 6600: 0.0006823799340054393\n",
      "Epoch 6800: 0.0006486983620561659\n",
      "Epoch 7000: 0.0006179834017530084\n",
      "Epoch 7200: 0.0005898703821003437\n",
      "Epoch 7400: 0.0005640517920255661\n",
      "Epoch 7600: 0.0005402688402682543\n",
      "Epoch 7800: 0.0005182945751585066\n",
      "Epoch 8000: 0.0004979388322681189\n",
      "Epoch 8200: 0.0004790328093804419\n",
      "Epoch 8400: 0.0004614315112121403\n",
      "Epoch 8600: 0.00044500769581645727\n",
      "Epoch 8800: 0.0004296518163755536\n",
      "Epoch 9000: 0.0004152648616582155\n",
      "Epoch 9200: 0.0004017602186650038\n",
      "Epoch 9400: 0.0003890618681907654\n",
      "Epoch 9600: 0.0003771009505726397\n",
      "Epoch 9800: 0.0003658173664007336\n"
     ]
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)\n",
    "    for epoch in range(10000):\n",
    "        erro_medio = 0\n",
    "        _, loss = sess.run([otimizador, erro], feed_dict={x_ph: x, y_ph: y})\n",
    "        \n",
    "        if epoch % 200 == 0:\n",
    "            erro_medio += loss / 4\n",
    "            print('Epoch {}: {}'.format(epoch, erro_medio))\n",
    "    \n",
    "    w_final, bias_final = sess.run([w, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden': array([[-6.3256917, -2.48976  , -6.0571938],\n",
       "        [-5.522573 ,  5.8612833,  3.3859425]], dtype=float32),\n",
       " 'output': array([[-7.111556 ],\n",
       "        [-7.116505 ],\n",
       "        [ 7.5502524]], dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden': array([ 1.7153709 , -0.00413651, -1.0670974 ], dtype=float32),\n",
       " 'output': array([3.7018795], dtype=float32)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01900709],\n",
       "       [0.96527964],\n",
       "       [0.9566862 ],\n",
       "       [0.04732471]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "hidden_layer_predict = tf.add(tf.matmul(x, w_final['hidden']), bias_final['hidden'])\n",
    "hidden_layer_result_predict = tf.sigmoid(hidden_layer_predict)\n",
    "\n",
    "output_layer_predict = tf.add(tf.matmul(hidden_layer_result_predict, w_final['output']), bias_final['output'])\n",
    "output_layer_result_predict = tf.sigmoid(output_layer_predict)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)\n",
    "    previsoes = sess.run(output_layer_result_predict)\n",
    "\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> \n",
    "### 2.2 Classificação Multiclasse (Base Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brunomaciel/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/brunomaciel/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Pre processamento\n",
    "scaler_x = StandardScaler()\n",
    "x = scaler_x.fit_transform(x)\n",
    "\n",
    "encoder = OneHotEncoder(categorical_features=[0])\n",
    "y = encoder.fit_transform(y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrutura da RNN\n",
    "input_neurons = x.shape[1]\n",
    "hidden_neurons = 4\n",
    "output_neurons = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define os placeholders de entrada e saída\n",
    "x_ph = tf.placeholder(dtype=tf.float32, shape=(None, input_neurons), name='x_placeholder')\n",
    "y_ph = tf.placeholder(dtype=tf.float32, shape=(None, output_neurons), name='y_placeholder')\n",
    "\n",
    "# Inicializa os pesos e bias\n",
    "w = {'hidden': tf.Variable(tf.random_uniform(shape=[input_neurons, hidden_neurons]), name='w_hidden'),\n",
    "     'output': tf.Variable(tf.random_uniform(shape=[hidden_neurons, output_neurons]), name='w_output')}\n",
    "\n",
    "bias = {'hidden': tf.Variable(tf.random_uniform(shape=[hidden_neurons]), name='bias_hidden'),\n",
    "        'output': tf.Variable(tf.random_uniform(shape=[output_neurons]), name='bias_output')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, w, bias):\n",
    "    hidden_layer = tf.add(tf.matmul(x, w['hidden']), bias['hidden'])\n",
    "    hidden_layer_result = tf.nn.relu(hidden_layer)\n",
    "\n",
    "    output_layer = tf.add(tf.matmul(hidden_layer_result, w['output']), bias['output'])\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo de FeedForward\n",
    "output_layer = mlp(x_ph, w, bias)\n",
    "\n",
    "# Calculo do Erro\n",
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer, labels=y_ph))\n",
    "\n",
    "# Processo de BackPropagation\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate=0.001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parametros do treinamento\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2.2402146962972784\n",
      "Epoch 501: 0.04957659456592339\n",
      "Epoch 1001: 0.03702863845795106\n",
      "Epoch 1501: 0.035877410142207876\n",
      "Epoch 2001: 0.03546482137776016\n",
      "Epoch 2501: 0.03525346525622388\n"
     ]
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(var_init)\n",
    "    for epoch in range(EPOCHS):\n",
    "        erro_medio = 0\n",
    "        n_batches = int(len(x_train) / BATCH_SIZE)\n",
    "        x_inBatches = np.array_split(x_train, n_batches) # Divide dados de treinamentos em batches\n",
    "        y_inBatches = np.array_split(y_train, n_batches)\n",
    "        \n",
    "        for i in range(n_batches):\n",
    "            _, loss = sess.run([otimizador, erro], feed_dict={x_ph: x_inBatches[i], y_ph: y_inBatches[i]})\n",
    "            erro_medio += loss / n_batches\n",
    "            \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch {}: {}'.format(epoch+1, erro_medio))\n",
    "    \n",
    "    w_final, bias_final = sess.run([w, bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "previsoes = mlp(x_ph, w_final, bias_final)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    r1 = sess.run(previsoes, feed_dict={x_ph: x_test})\n",
    "    r2 = sess.run(tf.nn.softmax(r1)) # resposta em probabilidade\n",
    "    r3 = sess.run(tf.argmax(r2, axis=1)) # resposta final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1d = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = accuracy_score(y_test_1d, r3)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> \n",
    "### 2.3 Classificação Binária com Estimators (Base Censo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('census.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>final-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loos</th>\n",
       "      <th>hour-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  final-weight   education  education-num  \\\n",
       "0   39          State-gov         77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc         83311   Bachelors             13   \n",
       "2   38            Private        215646     HS-grad              9   \n",
       "3   53            Private        234721        11th              7   \n",
       "4   28            Private        338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loos  hour-per-week  native-country  income  \n",
       "0          2174             0             40   United-States   <=50K  \n",
       "1             0             0             13   United-States   <=50K  \n",
       "2             0             0             40   United-States   <=50K  \n",
       "3             0             0             40   United-States   <=50K  \n",
       "4             0             0             40            Cuba   <=50K  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão entre atributos previsores e target\n",
    "x = data.drop('income', axis=1)\n",
    "y = data['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessamento nas colunas\n",
    "\n",
    "# Label encoder da variavel target\n",
    "y = y.map({' >50K': 1, ' <=50K' : 0})\n",
    "\n",
    "# Atributos categoricos\n",
    "workclass_col = tf.feature_column.categorical_column_with_hash_bucket(key='workclass', hash_bucket_size=100)\n",
    "education_col = tf.feature_column.categorical_column_with_hash_bucket(key='education', hash_bucket_size=100)\n",
    "marital_col = tf.feature_column.categorical_column_with_hash_bucket(key='marital-status', hash_bucket_size=100)\n",
    "occupation_col = tf.feature_column.categorical_column_with_hash_bucket(key='occupation', hash_bucket_size=100)\n",
    "relationship_col = tf.feature_column.categorical_column_with_hash_bucket(key='relationship', hash_bucket_size=100)\n",
    "race_col = tf.feature_column.categorical_column_with_hash_bucket(key='race', hash_bucket_size=100)\n",
    "country_col = tf.feature_column.categorical_column_with_hash_bucket(key='native-country', hash_bucket_size=100)\n",
    "sex_col = tf.feature_column.categorical_column_with_vocabulary_list(key='sex', vocabulary_list=[' Male', ' Female'])\n",
    "\n",
    "embedded_workclass = tf.feature_column.embedding_column(workclass_col, dimension=data['workclass'].unique().shape[0])\n",
    "embedded_education = tf.feature_column.embedding_column(education_col, dimension=data['education'].unique().shape[0])\n",
    "embedded_marital = tf.feature_column.embedding_column(marital_col, dimension=data['marital-status'].unique().shape[0])\n",
    "embedded_occupation = tf.feature_column.embedding_column(occupation_col, dimension=data['occupation'].unique().shape[0])\n",
    "embedded_relationship = tf.feature_column.embedding_column(relationship_col, dimension=data['relationship'].unique().shape[0])\n",
    "embedded_race = tf.feature_column.embedding_column(race_col, dimension=data['race'].unique().shape[0])\n",
    "embedded_country = tf.feature_column.embedding_column(country_col, dimension=data['native-country'].unique().shape[0])\n",
    "embedded_sex = tf.feature_column.embedding_column(sex_col, dimension=data['sex'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos numéricos\n",
    "age_col = tf.feature_column.numeric_column(key='age')\n",
    "weight_col = tf.feature_column.numeric_column(key='final-weight')\n",
    "educationNum_col = tf.feature_column.numeric_column(key='education-num')\n",
    "capGain_col = tf.feature_column.numeric_column(key='capital-gain')\n",
    "capLoos_col = tf.feature_column.numeric_column(key='capital-loos')\n",
    "hour_col = tf.feature_column.numeric_column(key='hour-per-week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = [age_col, embedded_workclass, weight_col, embedded_education, educationNum_col, embedded_marital,\n",
    "           embedded_occupation, embedded_relationship, embedded_race, embedded_sex, capGain_col, capLoos_col,\n",
    "           hour_col, embedded_country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão entre dados treino e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcao_train = tf.estimator.inputs.pandas_input_fn(x=x_train, y=y_train,\n",
    "                                                  batch_size=32, num_epochs=None, shuffle=True)\n",
    "funcao_test = tf.estimator.inputs.pandas_input_fn(x=x_test, y=y_test, \n",
    "                                                  batch_size=32, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = tf.estimator.DNNClassifier(hidden_units=[8,8], feature_columns=colunas, n_classes=2)\n",
    "classificador.train(input_fn=funcao_train, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/brunomaciel/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2029: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/brunomaciel/opt/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:619: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprected. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-07T14:58:50Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/ps/3gh7bfwd77b_xjwn226rnrqw0000gn/T/tmpl79pg6ay/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 3.12126s\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-07-14:58:53\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.77152216, accuracy_baseline = 0.7547344, auc = 0.5519725, auc_precision_recall = 0.5574247, average_loss = 9.238142, global_step = 10000, label/mean = 0.24526563, loss = 294.92618, precision = 0.8761468, prediction/mean = 0.022699889, recall = 0.07971619\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /var/folders/ps/3gh7bfwd77b_xjwn226rnrqw0000gn/T/tmpl79pg6ay/model.ckpt-10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.77152216,\n",
       " 'accuracy_baseline': 0.7547344,\n",
       " 'auc': 0.5519725,\n",
       " 'auc_precision_recall': 0.5574247,\n",
       " 'average_loss': 9.238142,\n",
       " 'label/mean': 0.24526563,\n",
       " 'loss': 294.92618,\n",
       " 'precision': 0.8761468,\n",
       " 'prediction/mean': 0.022699889,\n",
       " 'recall': 0.07971619,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.evaluate(input_fn=funcao_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> \n",
    "### 2.3.1 Padronização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização: \n",
    " - $ x_{norm} = \\frac{ x - min(x)} { max(x) - min(x)} $\n",
    " - $ 0 \\leq x_{norm} \\leq 1 $\n",
    "\n",
    "Padronização: \n",
    " - $ x_{std} = \\frac{ x - mean(x)} { std(x)} $\n",
    " - permite valores negativos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_AVG, AGE_STDDEV = data.age.mean(), data.age.std()\n",
    "weight_AVG, weight_STDDEV = data.age.mean(), data['final-weight'].std()\n",
    "educationNum_AVG, educationNum_STDDEV = data.age.mean(), data['education-num'].std()\n",
    "capGain_AVG, capGain_STDDEV = data.age.mean(), data['capital-gain'].std()\n",
    "CAPLOOS_AVG, CAPLOOS_STDDEV = data.age.mean(), data['capital-loos'].std()\n",
    "HOUR_AVG, HOUR_STDDEV = data.age.mean(), data['hour-per-week'].std()\n",
    "\n",
    "def padroniza_age(valor):\n",
    "    # x = (x - mean(x)) / std_dev(x)\n",
    "    numerador = tf.subtract(tf.cast(valor, tf.float32), tf.constant(AGE_AVG))\n",
    "    return tf.divide(numerador, tf.constant(AGE_STDDEV))\n",
    "\n",
    "def padroniza_weight(valor):\n",
    "    numerador = tf.subtract(tf.cast(valor, tf.float32), tf.constant(weight_AVG))\n",
    "    return tf.divide(numerador, tf.constant(weight_STDDEV))\n",
    "\n",
    "def padroniza_education(valor):\n",
    "    numerador = tf.subtract(tf.cast(valor, tf.float32), tf.constant(educationNum_AVG))\n",
    "    return tf.divide(numerador, tf.constant(educationNum_STDDEV))\n",
    "\n",
    "def padroniza_capGain(valor):\n",
    "    numerador = tf.subtract(tf.cast(valor, tf.float32), tf.constant(capGain_AVG))\n",
    "    return tf.divide(numerador, tf.constant(capGain_STDDEV))\n",
    "\n",
    "def padroniza_capLoos(valor):\n",
    "    numerador = tf.subtract(tf.cast(valor, tf.float32), tf.constant(CAPLOOS_AVG))\n",
    "    return tf.divide(numerador, tf.constant(CAPLOOS_STDDEV))\n",
    "\n",
    "def padroniza_hour(valor):\n",
    "    numerador = tf.subtract(tf.cast(valor, tf.float32), tf.constant(HOUR_AVG))\n",
    "    return tf.divide(numerador, tf.constant(HOUR_STDDEV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atributos numéricos\n",
    "age_col = tf.feature_column.numeric_column(key='age', normalizer_fn=padroniza_age)\n",
    "weight_col = tf.feature_column.numeric_column(key='final-weight', normalizer_fn=padroniza_weight)\n",
    "educationNum_col = tf.feature_column.numeric_column(key='education-num', normalizer_fn=padroniza_education)\n",
    "capGain_col = tf.feature_column.numeric_column(key='capital-gain', normalizer_fn=padroniza_capGain)\n",
    "capLoos_col = tf.feature_column.numeric_column(key='capital-loos', normalizer_fn=padroniza_capLoos)\n",
    "hour_col = tf.feature_column.numeric_column(key='hour-per-week', normalizer_fn=padroniza_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/> \n",
    "## 3. Regressão com Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21613, 21)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('house_prices.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
       "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
       "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0           0   \n",
       "1  538000.0         3       2.25         2570      7242     2.0           0   \n",
       "2  180000.0         2       1.00          770     10000     1.0           0   \n",
       "3  604000.0         4       3.00         1960      5000     1.0           0   \n",
       "4  510000.0         3       2.00         1680      8080     1.0           0   \n",
       "\n",
       "   view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  \\\n",
       "0     0          3      7        1180              0      1955             0   \n",
       "1     0          3      7        2170            400      1951          1991   \n",
       "2     0          3      6         770              0      1933             0   \n",
       "3     0          5      7        1050            910      1965             0   \n",
       "4     0          3      8        1680              0      1987             0   \n",
       "\n",
       "   zipcode      lat     long  \n",
       "0    98178  47.5112 -122.257  \n",
       "1    98125  47.7210 -122.319  \n",
       "2    98028  47.7379 -122.233  \n",
       "3    98136  47.5208 -122.393  \n",
       "4    98074  47.6168 -122.045  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_columns = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', \n",
    "           'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', \n",
    "           'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long']\n",
    "data = pd.read_csv('house_prices.csv', usecols=use_columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('price', axis=1)\n",
    "y = data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre processamento dos dados\n",
    "scaler_x = MinMaxScaler()\n",
    "x_scaled = scaler_x.fit_transform(x)\n",
    "x_scaled = pd.DataFrame(x_scaled, columns=x.columns)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "y_scaled = pd.Series(y_scaled.reshape(-1,), name='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria as colunas de atributos previsores\n",
    "colunas = [tf.feature_column.numeric_column(key=col) for col in use_columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_scaled, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as funções de treinamento e previsão\n",
    "funcao_train = tf.estimator.inputs.pandas_input_fn(x=x_train, y=y_train, batch_size=32, num_epochs=None, shuffle=True)\n",
    "\n",
    "funcao_predict = tf.estimator.inputs.pandas_input_fn(x=x_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/ps/3gh7bfwd77b_xjwn226rnrqw0000gn/T/tmp0spmftk0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/ps/3gh7bfwd77b_xjwn226rnrqw0000gn/T/tmp0spmftk0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Cria o regressor\n",
    "regressor = tf.estimator.DNNRegressor(hidden_units=(8,8,8), feature_columns=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza o treinamento\n",
    "regressor.train(input_fn=funcao_train, steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/ps/3gh7bfwd77b_xjwn226rnrqw0000gn/T/tmp0spmftk0/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'predictions': array([0.02033477], dtype=float32)},\n",
       " {'predictions': array([0.02544899], dtype=float32)},\n",
       " {'predictions': array([0.04228958], dtype=float32)},\n",
       " {'predictions': array([0.03751269], dtype=float32)},\n",
       " {'predictions': array([0.03039036], dtype=float32)}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao_gen = regressor.predict(input_fn=funcao_predict)\n",
    "list(previsao_gen)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/ps/3gh7bfwd77b_xjwn226rnrqw0000gn/T/tmp0spmftk0/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[230052.58],\n",
       "       [269048.56],\n",
       "       [397458.1 ],\n",
       "       ...,\n",
       "       [605558.25],\n",
       "       [947822.7 ],\n",
       "       [390693.5 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza a previsão\n",
    "previsoes_scaled = []\n",
    "for previsao in regressor.predict(input_fn=funcao_predict):\n",
    "    previsoes_scaled.append(previsao['predictions'])\n",
    "\n",
    "previsoes_scaled = np.array(previsoes_scaled).reshape(-1, 1)\n",
    "previsoes = scaler_y.inverse_transform(previsoes_scaled)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94218.02958002391"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_unscaled = scaler_y.inverse_transform(y_test.values.reshape(-1, 1))\n",
    "erro = mean_absolute_error(y_test_unscaled, previsoes)\n",
    "erro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
